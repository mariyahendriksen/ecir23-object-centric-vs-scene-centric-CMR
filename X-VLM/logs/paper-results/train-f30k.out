| distributed init (rank 0): env://
Creating model
### Loading pretrained vision encoder
Position interpolate vision_encoder.layers.0.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.0.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.1.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.1.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.2.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.3.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.4.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.5.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.6.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.7.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.8.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.9.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.10.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.11.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.12.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.13.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.14.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.15.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.16.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.17.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.3.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.3.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
### Loading pretrained text encoder
load checkpoint from /ivi/ilps/personal/mbiriuk/repro/X-VLM/4m_base_model_state_step_199999.th
missing_keys:  []
unexpected_keys:  ['bbox_head.0.weight', 'bbox_head.0.bias', 'bbox_head.1.weight', 'bbox_head.1.bias', 'bbox_head.3.weight', 'bbox_head.3.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias']
### Total Params:  213959547
Creating retrieval dataset
### output_dir,  output/zh/f30k
Start training
### data 2, batch size, 2 x 1
### lr_mult,  2
### num_training_steps,  1
### num_warmup_steps,  0
Train Epoch: [0] [0/1]  eta: 0:00:01  lr: 0.000000  loss_itm: 0.1326  loss_itc: 0.0005  time: 1.3984  data: 0.7209  max mem: 4160
Train Epoch: [0] Total time: 0:00:01 (1.4002 s / it)
Averaged stats: lr: 0.0000  loss_itm: 0.1326  loss_itc: 0.0005
Computing features for evaluation...
Evaluation: [0/2]  eta: 0:00:00    time: 0.0148  data: 0.0001  max mem: 4322
Evaluation: [1/2]  eta: 0:00:00    time: 0.0130  data: 0.0000  max mem: 4322
Evaluation: Total time: 0:00:00 (0.0134 s / it)
Evaluation: [0/2]  eta: 0:00:00    time: 0.0122  data: 0.0000  max mem: 4322
Evaluation: [1/2]  eta: 0:00:00    time: 0.0117  data: 0.0000  max mem: 4322
Evaluation: Total time: 0:00:00 (0.0120 s / it)
Evaluation time 0:00:00
Computing features for evaluation...
Evaluation: [ 0/10]  eta: 0:00:00    time: 0.0126  data: 0.0001  max mem: 4328
Evaluation: [ 9/10]  eta: 0:00:00    time: 0.0113  data: 0.0000  max mem: 4328
Evaluation: Total time: 0:00:00 (0.0114 s / it)
Evaluation: [ 0/10]  eta: 0:00:00    time: 0.0113  data: 0.0000  max mem: 4328
Evaluation: [ 9/10]  eta: 0:00:00    time: 0.0112  data: 0.0000  max mem: 4328
Evaluation: Total time: 0:00:00 (0.0112 s / it)
Evaluation time 0:00:01
Saved ranks to  output/zh/f30k/eval_ranks_i2t.pkl
Saved ranks to  output/zh/f30k/eval_ranks_t2i.pkl
{'txt_r1': 100.0, 'txt_r5': 100.0, 'txt_r10': 100.0, 'txt_r_mean': 100.0, 'img_r1': 100.0, 'img_r5': 100.0, 'img_r10': 100.0, 'img_r_mean': 100.0, 'r_mean': 100.0}
Saved ranks to  output/zh/f30k/eval_ranks_i2t.pkl
Saved ranks to  output/zh/f30k/eval_ranks_t2i.pkl
{'txt_r1': 90.0, 'txt_r5': 100.0, 'txt_r10': 100.0, 'txt_r_mean': 96.66666666666667, 'img_r1': 100.0, 'img_r5': 100.0, 'img_r10': 100.0, 'img_r_mean': 100.0, 'r_mean': 98.33333333333334}
{"train_lr": "0.00002", "train_loss_itm": "0.09966", "train_loss_itc": "0.05089", "val_txt_r1": 91.8145956607495, "val_txt_r5": 99.70414201183432, "val_txt_r10": 99.90138067061145, "val_txt_r_mean": 97.14003944773175, "val_img_r1": 81.38067061143984, "val_img_r5": 95.9171597633136, "val_img_r10": 97.8698224852071, "val_img_r_mean": 91.72255095332018, "val_r_mean": 94.43129520052597, "test_txt_r1": 91.9, "test_txt_r5": 99.2, "test_txt_r10": 99.9, "test_txt_r_mean": 97.0, "test_img_r1": 82.0, "test_img_r5": 96.46, "test_img_r10": 98.52, "test_img_r_mean": 92.32666666666665, "test_r_mean": 94.66333333333333, "epoch": 0}
best epoch: 0{"train_lr": "0.00001", "train_loss_itm": "0.19478", "train_loss_itc": "0.05013", "val_txt_r1": 100.0, "val_txt_r5": 100.0, "val_txt_r10": 100.0, "val_txt_r_mean": 100.0, "val_img_r1": 100.0, "val_img_r5": 100.0, "val_img_r10": 100.0, "val_img_r_mean": 100.0, "val_r_mean": 100.0, "test_txt_r1": 100.0, "test_txt_r5": 100.0, "test_txt_r10": 100.0, "test_txt_r_mean": 100.0, "test_img_r1": 100.0, "test_img_r5": 100.0, "test_img_r10": 100.0, "test_img_r_mean": 100.0, "test_r_mean": 100.0, "epoch": 0}
best epoch: 0{"train_lr": "0.00000", "train_loss_itm": "0.13263", "train_loss_itc": "0.00045", "val_txt_r1": 100.0, "val_txt_r5": 100.0, "val_txt_r10": 100.0, "val_txt_r_mean": 100.0, "val_img_r1": 100.0, "val_img_r5": 100.0, "val_img_r10": 100.0, "val_img_r_mean": 100.0, "val_r_mean": 100.0, "test_txt_r1": 90.0, "test_txt_r5": 100.0, "test_txt_r10": 100.0, "test_txt_r_mean": 96.66666666666667, "test_img_r1": 100.0, "test_img_r5": 100.0, "test_img_r10": 100.0, "test_img_r_mean": 100.0, "test_r_mean": 98.33333333333334, "epoch": 0}
best epoch: 0{"train_lr": "0.00000", "train_loss_itm": "0.13263", "train_loss_itc": "0.00045", "val_txt_r1": 100.0, "val_txt_r5": 100.0, "val_txt_r10": 100.0, "val_txt_r_mean": 100.0, "val_img_r1": 100.0, "val_img_r5": 100.0, "val_img_r10": 100.0, "val_img_r_mean": 100.0, "val_r_mean": 100.0, "test_txt_r1": 90.0, "test_txt_r5": 100.0, "test_txt_r10": 100.0, "test_txt_r_mean": 96.66666666666667, "test_img_r1": 100.0, "test_img_r5": 100.0, "test_img_r10": 100.0, "test_img_r_mean": 100.0, "test_r_mean": 98.33333333333334, "epoch": 0}
best epoch: 0### Time 0:00:07
NNODES,  1
NPROC_PER_NODE,  8
MASTER_ADDR,  SET_IT
MASTER_PORT,  12345
NODE_RANK,  0
### warning: the settings for distributed training is not filled (ignore this if you only use one node)
### warning: you have not set the path to hadoop_bin (ignore this if you don't use HDFS)
