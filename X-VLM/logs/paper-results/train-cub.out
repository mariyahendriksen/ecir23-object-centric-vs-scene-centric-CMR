Working with CUB!
Start training!
| distributed init (rank 0): env://
Creating model
### Loading pretrained vision encoder
Position interpolate vision_encoder.layers.0.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.0.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.1.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.1.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.2.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.3.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.4.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.5.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.6.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.7.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.8.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.9.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.10.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.11.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.12.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.13.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.14.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.15.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.16.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.2.blocks.17.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.3.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23
Position interpolate vision_encoder.layers.3.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23
### Loading pretrained text encoder
load checkpoint from /ivi/ilps/personal/mbiriuk/repro/X-VLM/4m_base_model_state_step_199999.th
missing_keys:  []
unexpected_keys:  ['bbox_head.0.weight', 'bbox_head.0.bias', 'bbox_head.1.weight', 'bbox_head.1.bias', 'bbox_head.3.weight', 'bbox_head.3.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias']
### Total Params:  213959547
Creating retrieval dataset
### output_dir,  output/zh/cub
Start training
### data 2, batch size, 2 x 1
### lr_mult,  2
### num_training_steps,  1
### num_warmup_steps,  0
Train Epoch: [0] [0/1]  eta: 0:00:01  lr: 0.000000  loss_itm: 0.0465  loss_itc: 0.0296  time: 1.4018  data: 0.6105  max mem: 4164
Train Epoch: [0] Total time: 0:00:01 (1.4030 s / it)
Averaged stats: lr: 0.0000  loss_itm: 0.0465  loss_itc: 0.0296
Computing features for evaluation...
Evaluation: [0/2]  eta: 0:00:00    time: 0.0162  data: 0.0001  max mem: 4327
Evaluation: [1/2]  eta: 0:00:00    time: 0.0140  data: 0.0000  max mem: 4327
Evaluation: Total time: 0:00:00 (0.0144 s / it)
Evaluation: [0/2]  eta: 0:00:00    time: 0.0130  data: 0.0000  max mem: 4327
Evaluation: [1/2]  eta: 0:00:00    time: 0.0123  data: 0.0000  max mem: 4327
Evaluation: Total time: 0:00:00 (0.0126 s / it)
Evaluation time 0:00:00
Computing features for evaluation...
Evaluation: [ 0/10]  eta: 0:00:00    time: 0.0142  data: 0.0001  max mem: 4334
Evaluation: [ 9/10]  eta: 0:00:00    time: 0.0119  data: 0.0000  max mem: 4334
Evaluation: Total time: 0:00:00 (0.0120 s / it)
Evaluation: [ 0/10]  eta: 0:00:00    time: 0.0117  data: 0.0000  max mem: 4334
Evaluation: [ 9/10]  eta: 0:00:00    time: 0.0116  data: 0.0000  max mem: 4334
Evaluation: Total time: 0:00:00 (0.0117 s / it)
Evaluation time 0:00:01
Saved ranks to  output/zh/cub/eval_ranks_i2t.pkl
Saved ranks to  output/zh/cub/eval_ranks_t2i.pkl
{'txt_r1': 100.0, 'txt_r5': 100.0, 'txt_r10': 100.0, 'txt_r_mean': 100.0, 'img_r1': 100.0, 'img_r5': 100.0, 'img_r10': 100.0, 'img_r_mean': 100.0, 'r_mean': 100.0}
Saved ranks to  output/zh/cub/eval_ranks_i2t.pkl
Saved ranks to  output/zh/cub/eval_ranks_t2i.pkl
{'txt_r1': 60.0, 'txt_r5': 80.0, 'txt_r10': 100.0, 'txt_r_mean': 80.0, 'img_r1': 50.0, 'img_r5': 80.0, 'img_r10': 100.0, 'img_r_mean': 76.66666666666667, 'r_mean': 78.33333333333334}
{"train_lr": "0.00002", "train_loss_itm": "0.46879", "train_loss_itc": "0.85435", "val_txt_r1": 6.228727025187202, "val_txt_r5": 17.59700476514636, "val_txt_r10": 25.7998638529612, "val_txt_r_mean": 16.541865214431585, "val_img_r1": 5.547991831177672, "val_img_r5": 18.17562968005446, "val_img_r10": 26.78692988427502, "val_img_r_mean": 16.83685046516905, "val_r_mean": 16.689357839800316, "test_txt_r1": 6.337535014005602, "test_txt_r5": 17.331932773109244, "test_txt_r10": 26.400560224089634, "test_txt_r_mean": 16.69000933706816, "test_img_r1": 5.917366946778712, "test_img_r5": 19.18767507002801, "test_img_r10": 27.906162464985993, "test_img_r_mean": 17.670401493930907, "test_r_mean": 17.180205415499536, "epoch": 0}
best epoch: 0{"train_lr": "0.00001", "train_loss_itm": "0.62565", "train_loss_itc": "1.62112", "val_txt_r1": 60.0, "val_txt_r5": 90.0, "val_txt_r10": 100.0, "val_txt_r_mean": 83.33333333333333, "val_img_r1": 70.0, "val_img_r5": 90.0, "val_img_r10": 100.0, "val_img_r_mean": 86.66666666666667, "val_r_mean": 85.0, "test_txt_r1": 30.0, "test_txt_r5": 90.0, "test_txt_r10": 100.0, "test_txt_r_mean": 73.33333333333333, "test_img_r1": 50.0, "test_img_r5": 80.0, "test_img_r10": 100.0, "test_img_r_mean": 76.66666666666667, "test_r_mean": 75.0, "epoch": 0}
best epoch: 0{"train_lr": "0.00000", "train_loss_itm": "0.04647", "train_loss_itc": "0.02955", "val_txt_r1": 100.0, "val_txt_r5": 100.0, "val_txt_r10": 100.0, "val_txt_r_mean": 100.0, "val_img_r1": 100.0, "val_img_r5": 100.0, "val_img_r10": 100.0, "val_img_r_mean": 100.0, "val_r_mean": 100.0, "test_txt_r1": 60.0, "test_txt_r5": 80.0, "test_txt_r10": 100.0, "test_txt_r_mean": 80.0, "test_img_r1": 50.0, "test_img_r5": 80.0, "test_img_r10": 100.0, "test_img_r_mean": 76.66666666666667, "test_r_mean": 78.33333333333334, "epoch": 0}
best epoch: 0### Time 0:00:07
NNODES,  1
NPROC_PER_NODE,  8
MASTER_ADDR,  SET_IT
MASTER_PORT,  12345
NODE_RANK,  0
### warning: the settings for distributed training is not filled (ignore this if you only use one node)
### warning: you have not set the path to hadoop_bin (ignore this if you don't use HDFS)
Done with training!
End of script!
